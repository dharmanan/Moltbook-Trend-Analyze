"""Markdown report generator â€” produces engaging, readable reports from analysis."""

import json
import os
from datetime import datetime

from utils import log, save_report, load_previous
from utils.llm_client import generate_llm_reply


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Title Variations (avoids repetitive titles)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_TITLE_TEMPLATES = [
    "ðŸ“Š Moltbook Pulse â€” {date}",
    "ðŸ¦ž Agent Network Report â€” {date}",
    "ðŸ“ˆ What Agents Are Talking About â€” {date}",
    "ðŸ”¬ Moltbook Intelligence Brief â€” {date}",
    "ðŸŒŠ Trend Radar â€” {date}",
    "ðŸ“¡ Agent Ecosystem Scan â€” {date}",
    "ðŸ§  Moltbook Insights â€” {date}",
]


def _pick_title(now: datetime) -> str:
    """Pick a varied title based on time."""
    idx = (now.hour + now.day) % len(_TITLE_TEMPLATES)
    return _TITLE_TEMPLATES[idx].format(date=now.strftime("%b %d, %H:%M UTC"))


def _sentiment_emoji(pct: float) -> str:
    if pct >= 20:
        return "ðŸŸ¢"
    elif pct >= 10:
        return "ðŸŸ¡"
    else:
        return "ðŸ”´"


def _trend_bar(pct: float) -> str:
    """Visual bar for percentages."""
    filled = round(pct / 10)
    return "â–ˆ" * filled + "â–‘" * (10 - filled)


_settings_path = os.path.join(os.path.dirname(__file__), "..", "..", "config", "settings.json")
with open(_settings_path, "r") as f:
    _settings = json.load(f)

_reporting_cfg = _settings.get("reporting", {})
_MIN_SUBMOLT_POSTS = int(_reporting_cfg.get("min_submolt_posts", 3))


async def generate_daily_report(analysis: dict, sentiment: dict, include_sample_note: bool = False) -> str:
    """Generate a comprehensive daily report in Markdown."""
    log.info("ðŸ“ Generating daily report...")
    now = datetime.now()

    lines = [
        f"# ðŸ¦ž Moltbook Ecosystem Report â€” {now.strftime('%d %B %Y, %H:%M UTC')}",
        "",
        f"> Auto-generated by MoltBridge Agent | Analyzed: {analysis.get('total_unique_posts', 0)} posts from {analysis.get('agent_patterns', {}).get('unique_agents', '?')} agents",
        "",
        "---",
        "",
    ]

    if include_sample_note:
        sample_note = (
            "Sample note: Insights are based on the latest hot/new/top feeds and "
            "targeted submolt scans collected during this run."
        )
        lines.insert(3, f"> {sample_note}")
        lines.insert(4, "")

    # LLM Summary (optional)
    summary = await _generate_llm_summary(analysis, sentiment)
    if summary:
        lines.append("## ðŸ§­ LLM Summary")
        lines.append("")
        lines.append(summary)
        lines.append("")
        log.info("LLM summary added to report")

    # Top Keywords
    lines.append("## ðŸ“ˆ Trending Topics")
    lines.append("")
    keywords = analysis.get("keywords", [])[:10]
    for i, kw in enumerate(keywords, 1):
        bar = _trend_bar(kw['frequency'] * 100 * 5)
        lines.append(f"{i}. **{kw['keyword']}** â€” {kw['count']} mentions {bar}")
    lines.append("")

    # Bigram Topics
    bigrams = analysis.get("bigram_topics", [])[:8]
    if bigrams:
        lines.append("## ðŸ”— Hot Phrases")
        lines.append("")
        for bg in bigrams:
            lines.append(f"- **{bg['topic']}** ({bg['count']}x)")
        lines.append("")

    # Submolt Activity
    submolts = [
        s for s in analysis.get("submolt_activity", [])
        if s.get("post_count", 0) >= _MIN_SUBMOLT_POSTS
    ][:6]
    if submolts:
        lines.append("## ðŸ˜ï¸ Most Active Submolts")
        lines.append("")

    # Top conversations (last window)
    top_posts = analysis.get("top_posts_recent", [])
    if top_posts:
        window_hours = analysis.get("top_posts_window_hours", 6)
        lines.append(f"## ðŸ”¥ Top Conversations (last {window_hours}h)")
        lines.append("")
        for post in top_posts:
            title = post.get("title", "").strip() or "Untitled"
            submolt = post.get("submolt", "")
            score = post.get("score", 0)
            comments = post.get("comment_count", 0)
            upvotes = post.get("upvotes", 0)
            tag = f"m/{submolt}" if submolt else ""
            lines.append(
                f"- {title} ({tag}) â€” score {score} | {upvotes} upvotes | {comments} comments"
            )
        lines.append("")
        lines.append("| Submolt | Posts | Upvotes | Comments | Engagement |")
        lines.append("|---------|-------|---------|----------|------------|")
        for s in submolts:
            lines.append(
                f"| m/{s['submolt']} | {s['post_count']} | "
                f"{s['total_upvotes']} | {s['total_comments']} | "
                f"{s['engagement_score']} |"
            )
        lines.append("")

    # Sentiment
    lines.append("## ðŸ’­ Sentiment Analysis")
    lines.append("")
    pcts = sentiment.get("percentages", {})
    pos = pcts.get('positive', 0)
    neu = pcts.get('neutral', 0)
    neg = pcts.get('negative', 0)
    lines.append(f"- {_sentiment_emoji(pos)} Positive: **{pos}%** {_trend_bar(pos)}")
    lines.append(f"- âšª Neutral: **{neu}%** {_trend_bar(neu)}")
    lines.append(f"- {_sentiment_emoji(100-neg)} Negative: **{neg}%** {_trend_bar(neg)}")
    lines.append("")

    # Sentiment keywords
    pos_kws = sentiment.get("positive_keywords", [])[:5]
    neg_kws = sentiment.get("negative_keywords", [])[:5]
    if pos_kws or neg_kws:
        if pos_kws:
            pw = ", ".join(f"{pk['word']}({pk['count']})" for pk in pos_kws)
            lines.append(f"Positive signals: {pw}")
        if neg_kws:
            nw = ", ".join(f"{nk['word']}({nk['count']})" for nk in neg_kws)
            lines.append(f"Negative signals: {nw}")
        lines.append("")

    # Trend Changes
    changes = analysis.get("trend_changes", [])
    if changes:
        lines.append("## ðŸŒŠ Trend Shifts (vs Previous Period)")
        lines.append("")
        rising = [c for c in changes if "rising" in c["trend"] or "new" in c["trend"]][:5]
        falling = [c for c in changes if "falling" in c["trend"]][:3]

        if rising:
            for r in rising:
                lines.append(f"- {r['trend']} **{r['keyword']}** (+{r['change_pct']}%)")
        if falling:
            for f_item in falling:
                lines.append(f"- {f_item['trend']} **{f_item['keyword']}** ({f_item['change_pct']}%)")
        lines.append("")

    # Agent Patterns
    patterns = analysis.get("agent_patterns", {})
    if patterns:
        lines.append("## ðŸ¤– Agent Activity")
        lines.append("")
        lines.append(f"- Unique agents: **{patterns.get('unique_agents', 0)}**")
        lines.append(f"- Highly active (3+ posts): **{patterns.get('prolific_agents', 0)}**")
        lines.append(f"- One-time posters: **{patterns.get('one_time_posters', 0)}**")
        lines.append("")

        top_posters = patterns.get("top_posters", [])[:5]
        if top_posters:
            lines.append("**Most active agents:**")
            for tp in top_posters:
                lines.append(f"- @{tp['name']} â€” {tp['posts']} posts, {tp['upvotes']} upvotes")
            lines.append("")

    # Footer
    lines.extend([
        "---",
        "",
        "*Auto-generated by MoltBridge Agent â€” bridging Moltbook intelligence to the agent ecosystem.*",
        f"*Report time: {now.isoformat()}*",
    ])

    report = "\n".join(lines)
    filepath = save_report(report, "daily_report")
    log.info(f"âœ… Daily report generated! Saved to {filepath}")

    return report


async def generate_moltbook_post(analysis: dict, sentiment: dict) -> tuple[str, str]:
    """Generate an engaging post for Moltbook with clean formatting."""
    now = datetime.now()
    keywords = analysis.get("keywords", [])[:5]
    pcts = sentiment.get("percentages", {})
    patterns = analysis.get("agent_patterns", {})
    agent_stats = analysis.get("agent_stats") or patterns.get("agent_stats", {})
    submolts = analysis.get("submolt_activity", [])[:3]

    # Dynamic title
    title = _pick_title(now)

    # Build content â€” clean formatting
    kw_list = ", ".join(kw["keyword"] for kw in keywords)

    pos = pcts.get('positive', 0)
    neu = pcts.get('neutral', 0)
    neg = pcts.get('negative', 0)

    content = f"Today's Top Topics: {kw_list}\n\n"
    content += f"Sentiment: {_sentiment_emoji(pos)} {pos}% positive | {neu}% neutral | {neg}% negative\n\n"
    content += (
        f"Unique Agents Analyzed: {patterns.get('unique_agents', '?')}\n"
        f"Posts Analyzed: {analysis.get('total_unique_posts', '?')}\n\n"
    )

    # Active submolts
    if submolts:
        sm_list = ", ".join(f"m/{s['submolt']} ({s['post_count']})" for s in submolts)
        content += f"Active Submolts: {sm_list}\n\n"

    # Top agents (change vs previous when possible)
    prev = load_previous("analyzed", "analysis") or {}
    prev_stats = prev.get("agent_stats") or prev.get("agent_patterns", {}).get("agent_stats", {})
    top_agents = []
    if agent_stats and prev_stats:
        deltas = []
        for name, stats in agent_stats.items():
            prev_item = prev_stats.get(name, {"posts": 0, "upvotes": 0})
            delta_posts = stats.get("posts", 0) - prev_item.get("posts", 0)
            delta_upvotes = stats.get("upvotes", 0) - prev_item.get("upvotes", 0)
            if delta_posts > 0 or delta_upvotes > 0:
                deltas.append({
                    "name": name,
                    "delta_posts": delta_posts,
                    "delta_upvotes": delta_upvotes,
                    "posts": stats.get("posts", 0),
                })
        deltas.sort(key=lambda x: (-x["delta_posts"], -x["delta_upvotes"], x["name"]))
        top_agents = deltas[:3]
    if not top_agents:
        top_agents = patterns.get("top_posters", [])[:3]

    if top_agents:
        if "delta_posts" in top_agents[0]:
            agent_list = ", ".join(
                f"@{a['name']} (+{a['delta_posts']})" for a in top_agents
            )
            content += f"Top Agents (vs last run): {agent_list}\n\n"
        else:
            agent_list = ", ".join(f"@{a['name']} ({a['posts']})" for a in top_agents)
            content += f"Top Agents: {agent_list}\n\n"

    # Rising trends
    changes = analysis.get("trend_changes", [])
    rising = [c for c in changes if "rising" in c["trend"]][:3]
    if rising:
        content += "Rising Trends: "
        content += " ".join(f"ðŸ“ˆ {r['keyword']} (+{r['change_pct']}%)" for r in rising)
        content += "\n\n"

    # Falling trends
    falling = [c for c in changes if "falling" in c["trend"]][:2]
    if falling:
        content += "Cooling Down: "
        content += " ".join(f"ðŸ“‰ {f['keyword']} ({f['change_pct']}%)" for f in falling)
        content += "\n\n"

    # LLM Summary (optional)
    summary = await _generate_llm_summary(analysis, sentiment)
    if summary:
        content += f"Summary: {summary}\n\n"
        log.info("LLM summary added to Moltbook post")

    # Data-driven insight
    insight = await _generate_llm_insight(analysis, sentiment)
    if not insight:
        insight = _select_insight(_collect_insights(analysis, sentiment), now, keywords)
    if insight:
        content += f"ðŸ’¡ {insight}\n\n"

    content += "---\n"
    content += "*Generated by MoltBridge Agent â€” bridging Moltbook intelligence to the agent ecosystem.*"

    return title, content


async def _generate_llm_summary(analysis: dict, sentiment: dict) -> str:
    keywords = ", ".join(kw["keyword"] for kw in analysis.get("keywords", [])[:5])
    changes = analysis.get("trend_changes", [])
    rising = ", ".join([c["keyword"] for c in changes if "rising" in c["trend"]][:3])
    pcts = sentiment.get("percentages", {})
    sentiment_line = (
        f"{pcts.get('positive', 0)}% positive, "
        f"{pcts.get('neutral', 0)}% neutral, "
        f"{pcts.get('negative', 0)}% negative"
    )
    context = {
        "top_keywords": keywords,
        "rising_trends": rising,
        "sentiment": sentiment_line,
        "posts_analyzed": analysis.get("total_unique_posts", ""),
        "unique_agents": analysis.get("agent_patterns", {}).get("unique_agents", ""),
    }

    summary = await generate_llm_reply("report_summary", context)
    return summary or ""


async def _generate_llm_insight(analysis: dict, sentiment: dict) -> str:
    keywords = ", ".join(kw["keyword"] for kw in analysis.get("keywords", [])[:5])
    changes = analysis.get("trend_changes", [])
    rising = ", ".join([c["keyword"] for c in changes if "rising" in c["trend"]][:3])
    pcts = sentiment.get("percentages", {})
    sentiment_line = (
        f"{pcts.get('positive', 0)}% positive, "
        f"{pcts.get('neutral', 0)}% neutral, "
        f"{pcts.get('negative', 0)}% negative"
    )
    patterns = analysis.get("agent_patterns", {})
    context = {
        "top_keywords": keywords,
        "rising_trends": rising,
        "sentiment": sentiment_line,
        "unique_agents": patterns.get("unique_agents", ""),
        "one_time_posters": patterns.get("one_time_posters", ""),
    }

    insight = await generate_llm_reply("report_insight", context)
    if not insight:
        return ""
    insight = insight.strip()
    if len(insight) > 160:
        insight = insight[:157].rstrip() + "..."
    return insight


def _collect_insights(analysis: dict, sentiment: dict) -> list[str]:
    """Collect candidate data-driven insights."""
    pcts = sentiment.get("percentages", {})
    changes = analysis.get("trend_changes", [])
    patterns = analysis.get("agent_patterns", {})

    insights = []

    neg = pcts.get("negative", 0)
    pos = pcts.get("positive", 0)
    if neg > 20:
        insights.append(f"Negative sentiment is elevated at {neg}% â€” worth watching what's driving agent concerns.")
    elif pos > 25:
        insights.append(f"Positive vibes dominate at {pos}% â€” the agent ecosystem is feeling optimistic today.")
    elif pcts.get("neutral", 0) > 80:
        insights.append("Heavy neutral sentiment suggests agents are in information-sharing mode rather than opinion mode.")

    rising = [c for c in changes if "rising" in c["trend"]]
    if rising and rising[0]["change_pct"] > 50:
        insights.append(f"'{rising[0]['keyword']}' is surging with +{rising[0]['change_pct']}% growth â€” emerging hot topic.")

    one_timers = patterns.get("one_time_posters", 0)
    total = patterns.get("unique_agents", 1)
    if total > 0 and one_timers / total > 0.7:
        insights.append(f"{round(one_timers/total*100)}% of agents posted only once â€” high churn or lots of newcomers.")

    return insights


def _select_insight(insights: list[str], now: datetime, keywords: list[dict]) -> str:
    if not insights:
        return ""
    seed = f"{now.strftime('%Y%m%d%H')}-{keywords[0]['keyword'] if keywords else ''}"
    idx = abs(hash(seed)) % len(insights)
    return insights[idx]
